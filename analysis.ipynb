{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from langdetect import detect\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/defalt/nltk_data', '/mnt/partition1/machine_learning/Bengali_Sentiment_Analysis_and_Classification/venv/nltk_data', '/mnt/partition1/machine_learning/Bengali_Sentiment_Analysis_and_Classification/venv/share/nltk_data', '/mnt/partition1/machine_learning/Bengali_Sentiment_Analysis_and_Classification/venv/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/defalt/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bengali Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"/mnt/partition1/machine_learning/Bengali_Sentiment_Analysis_and_Classification/dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Review\", \"Sentiment\"]]\n",
    "df.columns = [\"text\", \"label\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert labels to numeric values (0: Negative, 1: Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\"negative\": 0, \"positive\": 1}\n",
    "df[[\"label\"]] = df[[\"label\"]].apply(LabelEncoder().fit_transform)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Mixed-Language Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    print(f\"Before tokenized : {text}\")\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[\\d]+\", \"\", text)  # Remove numbers\n",
    "    text = re.sub(r\"[^\\w\\sঀ-৿.,!?₹$]\", \"\", text)  # Keep Bengali and English letters only\n",
    "    tokens = word_tokenize(text)  # Tokenize using NLTK\n",
    "    tokenized_text = \" \".join(tokens)  # Convert tokens back to string\n",
    "    print(f\"after tokenized : {tokenized_text}\")\n",
    "    return tokenized_text\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(preprocess_text)\n",
    "df[\"language\"] = df[\"text\"].apply(detect_language)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Hugging Face Dataset Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({\"text\": train_texts.tolist(), \"label\": train_labels.tolist()})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts.tolist(), \"label\": test_labels.tolist()})\n",
    "datasets = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(train_texts)\n",
    "X_test_tfidf = vectorizer.transform(test_texts)\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "svm_predictions = svm_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9098, Precision: 0.9023, F1 Score: 0.9023, Recall Score: 0.9736\n"
     ]
    }
   ],
   "source": [
    "svm_accuracy = accuracy_score(test_labels, svm_predictions)\n",
    "svm_precision = precision_score(test_labels, svm_predictions, average='weighted')\n",
    "svm_f1 = f1_score(test_labels, svm_predictions, average='weighted')\n",
    "svm_recall = recall_score(test_labels, svm_predictions)\n",
    "\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}, Precision: {svm_precision:.4f}, F1 Score: {svm_f1:.4f}, Recall Score: {svm_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BanglaBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('sagorsarker/bangla-bert-base')\n",
    "model = BertForSequenceClassification.from_pretrained('sagorsarker/bangla-bert-base', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Tokenizing the dataset for BanglaBERT\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "\n",
    "train_encodings = tokenize_data(train_texts.tolist())\n",
    "test_encodings = tokenize_data(test_texts.tolist())\n",
    "\n",
    "# Converting labels to tensor\n",
    "train_labels = torch.tensor(train_labels.values).to(device)\n",
    "test_labels = torch.tensor(test_labels.values).to(device)\n",
    "\n",
    "# Dataloader for BanglaBERT model\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training the BanglaBERT model\n",
    "\n",
    "for epoch in range(10):  # Training for 10 epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        # print(input_ids,' ',attention_mask,' ',labels,'\\n')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch: {epoch + 1}, Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "# Evaluating the BanglaBERT model\n",
    "model.eval()\n",
    "bangla_bert_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, _ = [b.to(device) for b in batch]\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        bangla_bert_predictions.extend(predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BanglaBERT Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BanglaBERT Model Metrics:\n",
      "Accuracy: 90.18%\n",
      "Precision: 90.92%\n",
      "Recall: 98.43%\n",
      "F1 Score: 94.53%\n"
     ]
    }
   ],
   "source": [
    "bangla_bert_predictions = bangla_bert_predictions.cpu().numpy() if torch.is_tensor(bangla_bert_predictions) else np.array(bangla_bert_predictions)\n",
    "test_labels = test_labels.cpu().numpy() if torch.is_tensor(test_labels) else np.array(test_labels)\n",
    "\n",
    "bangla_bert_accuracy = accuracy_score(test_labels, bangla_bert_predictions)\n",
    "bangla_bert_precision = precision_score(test_labels, bangla_bert_predictions)\n",
    "bangla_bert_recall = recall_score(test_labels, bangla_bert_predictions)\n",
    "bangla_bert_f1 = f1_score(test_labels, bangla_bert_predictions)\n",
    "\n",
    "print(\"BanglaBERT Model Metrics:\")\n",
    "print(f\"Accuracy: {bangla_bert_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {bangla_bert_precision * 100:.2f}%\")\n",
    "print(f\"Recall: {bangla_bert_recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {bangla_bert_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_prediction(text):\n",
    "    # Preprocess and tokenize the input text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "\n",
    "    svm_input = vectorizer.transform([preprocessed_text])\n",
    "    svm_prediction = svm_model.predict(svm_input)\n",
    "    svm_sentiment = 'Positive' if svm_prediction == 1 else 'Negative'\n",
    "\n",
    "\n",
    "    encoded_input = tokenizer(preprocessed_text, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n",
    "    \n",
    "    # Get prediction from BanglaBERT model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "        prediction = torch.argmax(output.logits, dim=1).cpu().numpy()[0]\n",
    "    \n",
    "    # Mapping predicted class to sentiment\n",
    "    bangla_bert_sentiment = 'Positive' if prediction == 1 else 'Negative'\n",
    "    return svm_sentiment, bangla_bert_sentiment\n",
    "\n",
    "# Example: Get live prediction\n",
    "user_input = input(\"Enter a product review for prediction: \")\n",
    "svm_result, bangla_bert_result = live_prediction(user_input)\n",
    "print(f\"SVM Prediction: The sentiment of the review is {svm_result}\")\n",
    "print(f\"BanglaBERT Prediction: The sentiment of the review is {bangla_bert_result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
